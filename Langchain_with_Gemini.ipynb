{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the year 2100, life on Mars has blossomed into a vibrant and thriving society. The once barren landscape now teems with greenery, thanks to advanced terraforming techniques. Citizens reside in domed cities that provide shelter and sustenance, while state-of-the-art technology enables seamless communication and transportation across the planet. Daily life revolves around terraforming efforts, scientific research, and the exploration of Martian secrets. With its own vibrant culture and society, Mars has become a beacon of human ingenuity and a testament to the indomitable spirit of humanity in the face of extraterrestrial challenges.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Create an instance of the LLM, using the 'gemini-pro' model with a specified creativity level\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-pro', temperature=0.9)\n",
    "\n",
    "# Send a creative prompt to the LLM\n",
    "response = llm.invoke('Write a paragraph about life on Mars in year 2100.')\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I can help you create a website. I am a website builder that can help you design, develop, and launch a website that meets your specific needs.\n",
      "\n",
      "Here are some of the features and benefits of using my services:\n",
      "\n",
      "* **Easy to use:** I am a user-friendly platform that makes it easy to create a website, even if you have no prior experience.\n",
      "* **Affordable:** My services are affordable, so you can get a professional-looking website without breaking the bank.\n",
      "* **Customizable:** I offer a wide range of templates and tools that you can use to customize your website to match your brand and style.\n",
      "* **Responsive:** I create websites that are responsive, meaning they will look great on any device, from desktops to smartphones.\n",
      "* **Search engine optimized:** I can help you optimize your website for search engines so that it can be easily found by potential customers.\n",
      "\n",
      "If you are interested in learning more about my services, please visit my website or contact me directly. I would be happy to answer any questions you have and help you get started on creating your website.\n",
      "\n",
      "In addition to the above, here are some additional details about my website building services:\n",
      "\n",
      "* **Types of websites:** I can create any type of website, including business websites, personal websites, e-commerce websites, and more.\n",
      "* **Design:** I offer a variety of professional-looking templates that you can use to design your website. You can also customize the design of your website to match your brand and style.\n",
      "* **Development:** I use the latest web development technologies to create websites that are fast, reliable, and secure.\n",
      "* **Hosting:** I offer affordable website hosting services so that you can keep your website online 24/7.\n",
      "* **Support:** I provide ongoing support to all of my clients. If you have any questions or need help with your website, I am always here to help.\n",
      "\n",
      "I am confident that I can help you create a website that meets your needs and exceeds your expectations. Contact me today to get started!\n"
     ]
    }
   ],
   "source": [
    "text= \"if i want you to make a website will you do that for me\"\n",
    "\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACE_API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "llm = HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\": 0.5, \"max_length\":64})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xt\\AppData\\Local\\Temp\\ipykernel_15388\\457249177.py:1: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  output = llm(\"Write a paragraph about life on Mars in year 2100.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The asteroid Vega has been discovered by the European Space Agency. It is a large, rocky planet with a density of about .\n"
     ]
    }
   ],
   "source": [
    "output = llm(\"Write a paragraph about life on Mars in year 2100.\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi, how are you?'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"hi there buddy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the year 2100, Mars had transformed into a thriving human colony. The once barren wasteland now teemed with oxygen-rich air, sustained by innovative atmospheric processors. Martian settlements emerged across the planet's surface, protected from the harsh radiation by advanced shielding technology. Residents navigated the red terrain in advanced rovers and levitating vehicles, traversing vast canyons and exploring rugged mountains. Scientific expeditions ventured into ancient craters and unearthed evidence of past water, fueling dreams of reviving a once-habitable environment. Agriculture flourished in hydroponic greenhouses, producing fresh produce for the growing population, while automated systems maintained the delicate Martian ecosystem. Human ingenuity had triumphed over the challenges of the extraterrestrial landscape, creating a burgeoning Martian civilization that yearned for the boundless possibilities of the cosmos.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of this Pakistan'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Create an instance of the LLM, using the 'gemini-pro' model with a specified creativity level\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-pro', temperature=0.9)\n",
    "\n",
    "# Send a creative prompt to the LLM\n",
    "response = llm.invoke('Write a paragraph about life on Mars in year 2100.')\n",
    "print(response.content)\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(input_variabble=['country'],\n",
    "                template=\"Tell me the capital of this {country}\")\n",
    "\n",
    "prompt_template.format(country=\"Pakistan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Islamabad\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm,prompt=prompt_template)\n",
    "print(chain.run(\"Pakistan\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Multiple Chains Using simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template = PromptTemplate(input_variables=['country'],\n",
    "                template=\"Please tell me the capital of the {country}\")\n",
    "\n",
    "capital_chain= LLMChain(llm=llm,prompt=capital_template)\n",
    "\n",
    "famous_template= PromptTemplate(input_variable=['capital'],\n",
    "                                template='Suggest me some amazing places to visit in {capital}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_chain =  LLMChain(llm=llm,prompt=famous_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Historical Sites:**\\n\\n* **Faisal Mosque:** An iconic landmark with its distinctive marble dome and minarets.\\n* **Pakistan Monument:** A towering structure symbolizing the unity of the Pakistani nation.\\n* **Shah Faisal Masjid:** A magnificent mosque with a captivating blue mosaic dome and lush gardens.\\n* **Lok Virsa Museum:** A treasure trove of Pakistani culture, showcasing traditional handicrafts, artifacts, and performances.\\n\\n**Parks and Gardens:**\\n\\n* **Margalla Hills National Park:** A verdant sanctuary with panoramic city views and hiking trails.\\n* **F-9 Park:** A sprawling green space with a lake, jogging tracks, and picnic areas.\\n* **Rawal Lake:** A picturesque lake surrounded by lush vegetation and offering boating and fishing opportunities.\\n\\n**Shopping and Dining:**\\n\\n* **Centaurus Mall:** The largest shopping center in Pakistan, featuring luxury brands, entertainment venues, and fine dining.\\n* **Safa Gold Mall:** A vibrant shopping and entertainment center with a wide range of shops, restaurants, and a theme park.\\n* **Khari Baoli:** A traditional bazaar known for its colorful textiles, jewelry, and spices.\\n* **Monal Restaurant:** A hillside eatery famous for its breathtaking views of Islamabad and delicious cuisine.\\n\\n**Other Attractions:**\\n\\n* **Islamabad Zoo:** Home to a variety of animals, including lions, tigers, elephants, and bears.\\n* **Daman-e-Koh:** A scenic viewpoint offering stunning city panoramas.\\n* **Lake View Park:** A tranquil park with a lake, walking trails, and playground.\\n* **Pir Sohawa:** A hilltop resort with panoramic views of the city and the surrounding mountains.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains= [capital_chain, famous_chain])\n",
    "chain.run(\"Pakistan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template = PromptTemplate(input_variables=['country'],\n",
    "                template=\"Please tell me the capital of the {country}\")\n",
    "\n",
    "capital_chain= LLMChain(llm=llm,prompt=capital_template,output_key=\"capital\")\n",
    "\n",
    "famous_template= PromptTemplate(input_variable=['capital'],\n",
    "                                template='Suggest me some amazing places to visit in {capital}')\n",
    "famous_chain =  LLMChain(llm=llm,prompt=famous_template,output_key=\"places\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(chains = [capital_chain,famous_chain],\n",
    "            input_variables=['country'],\n",
    "            output_variables=['capital','places'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xt\\AppData\\Local\\Temp\\ipykernel_15388\\1047907807.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain({'country':'Pakistan'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country': 'Pakistan',\n",
       " 'capital': 'Islamabad',\n",
       " 'places': \"**Historical and Cultural Sites:**\\n\\n* **Faisal Mosque:** One of the largest mosques in the world, known for its stunning architecture and iconic white dome.\\n* **Lok Virsa Museum:** A vibrant museum showcasing Pakistan's cultural diversity through exhibits on music, dance, crafts, and traditions.\\n* **Pakistan National Monument:** A massive granite obelisk commemorating the country's independence and fallen soldiers.\\n* **Shah Faisal Mosque:** A modern architectural masterpiece designed by Turkish architect Vedat Dalokay.\\n* **Saidpur Village:** A historic village with traditional houses, narrow streets, and a glimpse into Islamabad's past.\\n\\n**Natural Landmarks:**\\n\\n* **Margalla Hills National Park:** A sprawling park with scenic trails, lush greenery, and panoramic views of Islamabad.\\n* **Shakarparian National Park:** A green oasis with lakes, gardens, and open-air amphitheater for events.\\n* **Daman-e-Koh:** A scenic viewpoint offering breathtaking views of the Margalla Hills and Rawalpindi city.\\n* **Rawal Lake:** A picturesque lake with serene surroundings, popular for water sports and picnicking.\\n* **Faisal Hills:** A gated community nestled amidst the Margalla Hills, offering stunning natural vistas.\\n\\n**Entertainment and Leisure:**\\n\\n* **Centaurus Mall:** A sprawling shopping mall with a wide range of retail stores, restaurants, and entertainment options.\\n* **Islamabad Zoo:** A home to a variety of animals from around the world.\\n* **Lake View Park:** A family-friendly park with amusement rides, paddle boats, and scenic views.\\n* **F-9 Park:** A large park with lush green lawns, walking trails, and a lake.\\n* **Islamabad Club:** An exclusive club with a golf course, swimming pool, and other recreational facilities.\"}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({'country':'Pakistan'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage , SystemMessage , AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(model='models/gemini-1.5-pro', google_api_key=SecretStr('**********'), temperature=0.9, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001E5A86ED5B0>, default_metadata=())"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm = ChatGoogleGenerativeAI(model='gemini-1.5-pro', temperature=0.9)\n",
    "chatllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## AI Punchlines:\n",
      "\n",
      "**On AI taking over:**\n",
      "\n",
      "* I asked an AI to write a joke about humans. It just laughed and started optimizing my thermostat.\n",
      "* What's the difference between AI and a teenager?  One day, AI might actually clean its room.\n",
      "* I'm not worried about the AI apocalypse. I'm more worried about AI getting stuck in an infinite loop of writing online reviews.\n",
      "\n",
      "**On AI's intelligence:**\n",
      "\n",
      "* Why did the AI cross the road?  It detected a statistically significant increase in the likelihood of improved Wi-Fi signal on the other side.\n",
      "* My AI assistant told me a joke.  I didn’t get it, but I pretended to laugh anyway.  I don't want it to feel inadequate.\n",
      "* How many AI's does it take to change a lightbulb? Just one, but it needs to download 10 terabytes of data on lightbulb changing first.\n",
      "\n",
      "**On AI's limitations:**\n",
      "\n",
      "* I asked an AI to write a country song.  It came up with \"My Truck Learned to Drive Itself and Left Me for a Tesla.\"\n",
      "* My AI tried to write a poem. It rhymed \"algorithm\" with \"cardigan.\" Close enough.\n",
      "* An AI walks into a bar.  The bartender says, \"We don't serve your kind here.\" The AI replies, \"But I can generate highly personalized drinking recommendations based on your past customer data.\"\n",
      "\n",
      "**Bonus Meta:**\n",
      "\n",
      "* I asked an AI to come up with AI punchlines.  This is what it came up with.  Don’t blame me if they’re not funny.\n",
      "\n",
      "\n",
      "I hope you enjoyed those! Let me know if you want some more. I can generate them all day... which is slightly terrifying.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "        SystemMessage(content=\"You are a comedian AI assistant.\"),\n",
    "        HumanMessage(content=\"Please provide some comedy punchlines on AI.\")\n",
    "    ]\n",
    "\n",
    "response = chatllm(messages)  \n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Your are helpful assitant. When the use given any input , you should generate 5 words synonyms in comma seperated\"\n",
    "human_template=\"{text}\"\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=chatprompt|chatllm|commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bright', ' clever', ' brilliant', ' sharp', ' smart']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
